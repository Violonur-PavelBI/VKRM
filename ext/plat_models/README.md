# Репозиторий с сетями


## Структура Библиотеки:

На верхнем уровне в `__init__.py` импортируются из торча\плата базовые слои, например Conv2d, BatchNorm2d, RelU, PRelu, Softmax, Sigmoid и т.д
Там же на основе некой переменной окружения будет осуществляться переключение между торчом и платом, при изменении атрибута модуля `__all__`.
Структура репозитория:
models:
- basicblocks
- backbones
- heads
- attention
- functional
- utils
- networks
- necks

В `core.functional` предлагаю связать таким же образом как и в models операции над тензорами, которые будут подставляться в общий функционал базового класса,
тензора. Это необходимо для возможности использования синтаксического сахара, такого как: `x.softmax(...)`, `x.topk(...)` и тому подобных операций.
Помимо этого, в ней же будет связка и переключение между торчом\платом операций из nn.functional.

В `core.module` предполагаются аналоги торча такие как Sequential, ModuleList, ModuleDict для плата, которые в `__init__.py` верхнего уровня будут переключаться между платом и торчом. И другие утилиты.

В networks будут лежать готовые сети для использования. Т.е уже собранные или атомарные (как UNet, YOLOv3,YOLOv4 и т.п)

## Веса предобученных моделей

Веса моделей, предобученных на imagenet 1000 классов, будут храниться в папке */3010/Repin/pmodels/* . Обратиться к ним можно сначало по семейству сетей (resnet/senet/mobilenetv2), далее по наименнованию самой сети.

## Конвертирование и поддержка актуальности таблицы поддерживаемых архитектур

### Конструкторы архитектур
> 1. Конструктор целая сеть (атомарные). Архитектура описывается в networks в виде класса, со всеми необходимыми атрибутами передающиеся конструктору
ссылкой на статью и документацией.
> 2. Двух компонентный конструктор backbone - head\decoder. Вызывается с атомарным `backone`'ом и атомарным `head`'ом, они также имеют в своих конструкторах все необходимые атрибуты, и докстринг с ссылкой на статью.
> 3. Трёхкомпонентный конструктор, backbone - neck - head,
> 4. Многокомпонетный конструктор, атрибуты которого лежат в конфигурационном файле, (формат обсуждается). Предварительная документация составляется на основе документации отдельных архитектурных блоков и их параметров. В первую очередь необходим для проведения экспериментов с архитектурами, которые не протестированы, для последующего рефакторинга и переноса в п. 1 или 2.

### Отображение актуальной информации об тестировании на отдельных вычислительных устройствах

~Тут ссылку на models-common~

Основной механизм сборки архитектур для тестирования на устройствах происходит следующим образом:
> 1. Считываются заголовки (атрибут `__all__` файлов `__init__.py`) на уровнях networks, heads и backbones, baseblocks. Считываются исключения.
> 2. Проверяется, какие изменения появились в архитектурах с предыдущей итерации конвертирования.
> 3. Для всех *измененных* сетей и блоков [пересобираются бинарники и json'ы в формате Платформы](#описание-утилиты-конвертирования-для-упрощения-работы-с-репозиторием)
> 4. Измения актуализируются в таблице с информацией о работоспособности на устройствах.

Дополнительный механизм повторяет основной, но используются только исключения.
### Описание сохранения, хранения, загрузки чекпоинтов, предобученных весов и метадатты данного
#### sub Roadmap:
- [ ]  Общий конструктор, двух-трех компонентный, для сохранения общей конфигурации.
- [ ] `kernel_api.utils.savers` Обсудить перенос в `mcore`. Добавить и перенести описание.
- [ ]  Тесты в `models` и `mcore` (так как он не отсыкован) на сохранение чекпоинтов.
- [ ] Интерфейс сохранения\загрузки чекпоинтов (После обсуждения)

#### Concept:
Сохранения чекпоинтов в бд подразумевает наличие тегов у чекпоинтов, для поиска и фильтрации подходящих сетей, к тому же, `kernel_api.utils.saver` подразумевает правило на основе метрик либо других артефактов вычисления, по которому происходит сохраенение,  соотвественно при сохранении чекпоинтов можно по мимо вещей необходимых для загрузки модели, в saver'е сохраняем и метрики.
Так как части сети по логике можно также предобучать, и возможны сети с несколькими head'ами или даже с несколькими neck'ами, сам механизм загрузки и сохранения должен предусматривать частичную загрузку, например загрузка только head'а для данной задачи, либо `backbone + neck`
либо только `backbone`. Теги также должны позволять это делать.
К тому же было бы полезно знать о таких вещах как разрешение\я с которым обучалась сеть, число каналов, специфику каналов (RGB), (BGR), (RGBI), (RGB + mask), ряд параметров оптимизации (lr, wd) для того, чтобы не испортить веса, специфичные для задачи вещи (число классов, реальный размер анкеров, средний размер объекта в выборке и т.п), полезно было бы знать о занимаемой памяти GPU во время обучения, с выбранным батчем, и времени прогона батча
Такие блоки как `backbone + neck` скорее всего должны быть мултизадачными, а `head` - задаче-зависимый как и ранее.
Соответсвенно существующие предобученные веса также должны быть пересохранены с поддержкой общего формата (формат обсуждается).

Предварительно описание чекпоинта, сохраняемого в репозиторий моделей:
- Описание структуры модели (параметры конструктора);
- Значения метрик для данной архитектуры (Acc, MAP, L1, MIoU);
- Функция ошибки;
- Общее разрешение пространственное: (Н,W), (L), (D,H,W);
- Описание бэкбоуна:
  - Разрешение входное канальное $ C_{in} $;
  - Описание каналов "RGB", "RGB" + "mask";
- Описание головы:
  - Разрешение канальное ($ C_{out}, C_{num_classes}$);
  - Разрешение пространственное "1", "H/2, W/2", "H/8, W/8";
- Параметры оптимизации `lr`, `wd`, (текущие значения, если есть группы, то по группам) Использовавшийся алгоритм оптимизации;
- Размер батча, потребляемая память GPU;
- Оценка времени прямого прохода. (без построения графа, torch.no_grad);
- Оценка времени прямого и обратного прохода. (с расчетом градиента, градиент примитвнейшей функции, например `mean` от предсказания);


### Описание утилиты конвертирования для упрощения работы с репозиторием (DEPRECATED)
утилита принимает один из следующих аргументов:
1. Название сети, параметры инициализации сети
2. Название backbone и head\decoder'а
3. Конфигурационный файл архитектуры.
4. Дополнительные аргументы, (флаг переписывание json'а\бинарника, и т.п.);

Создает\обновляет папку со структуризированным именем, на основе первых трех пунктов, в ней находятся json и бинарный файл в формате Платформы, характеризующий сеть, а также примеры входного и выходного тензоров. Также информацию о версии (номер коммита) при котором архитектура была создана. И о предыдущих успешных номерах коммитов, прошедших пайплайн тестирования на различных устройствах.

### Конвертирование в платформу и обратно
Для того, чтобы модель конвертировалась в платформу, необходимо чтобы все классы, являющиеся дочерними от `nn.Module`, были отнаследованы от `mcore.Module`. В таком случае, у всех моделей будут существовать методы, `.toplatform` и `.fromplatform` необходимые для иморта\экспорта моделей. (work in progress). _*Добавить сюда доки данных методов*_.
В качестве костыля, если уж очень надо (по рукам бить будем, использовать только во время пожара), существует такой прием: В скрипте входа, в заголовке импортируем торч, и подменяем `nn.Module` на `mcore.Module`, после этого импортируем всё остальное.

### Описание Формата Таблицы
Таблица содержит в себе следующие столбцы:
1. Название сети
2. Название backbone'а
3. Название head\decoder'а
4. Список слоев, входящих в состав сети
5. Перечень вычислителей с отмеченным статусом поддержки
6. Информация о статусе изменения - дата последнего изменения кода сети/ссылка на комит

При этом поля 1-3 могут быть заполнены не все, но как минимум одно будет не пустое.
json и бинарник сети, совместно с входными и выходными тензорами будут размещаться в папке в хранилище. Имя папки будет формироваться из суммы первых трех столбцов.
Входные и выходные тензора будут сохраняться для нескольких разрешений (не менее 3-х).
Приоритет заполнения таблицы из сетей входящих в ТР и отдельных backbone'ов и head\decoder'ов и слоёв, без расмотрения их комбинаций.

### Описание Тулзы.

## Тестирование

Для проверки правильности полученных сетей реализованы тесты. В test.networks можно проверить работу сетей для задача классификации и сегментации.

## Roadmap

В для checkpoint'ов, нужно добавить такую метадату:
> 1. Версия репозитория на момент сохранения весов
> 2. Некий указатель на код и параметры сборщика, на сборщик модели. Либо скрипт\метод\класс\функция из networks
> 3. Датасет на котором осуществлялось обучение
> 4. Полученные метрики.
> 5. Дополнительные данные по обучению, если нужно. Пример:
>> **Максимальный `lr` для старта обучения, чтобы не попортить сразу веса.**
>> Какой precision использовался,fp16(mixed) или fp32.

Дерево будет для подрепозитория чекпоинтов:
> бэкбон:
>>  {название сети}:
>>>		{веса_стеки_для_базы_данных}
>>>     {метадата}

> сеть:
>> {название задачи}:
>>>     {название сети}
>>>>       {веса_стеки_для_базы_данных}
>>>>       {метадата}

Структура репозитория хранения предобученных весов имеет следующий вид:
 - backbones
 > название сети
 >> веса_сети_для_базы_данных + метадата
 - networks
 > тип ТР
 >> название сети
 >>> веса_сети_для_базы_данных + метадата

### На подумать

1. Как проверять/фиксировать изменения в компонентах блоков/сети при мердже (как вариант на основе хешей кода, начиная с верхнего уровня классов архитектур - до уровней слоёв)
2. Приоритет блока/слоя на основе частоты встречаемости в архитектурах, входящих в состав таблицы.
